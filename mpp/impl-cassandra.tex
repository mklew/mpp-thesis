%!TEX root = ../thesis.tex

\chapter{Implementation of the algorithm in Cassandra}\label{sec:mpp:impl}
% Implementation in Cassandra (concrete part, implementation in Cassandra)
In this section the discussion will point to implementation details of the algorithm and its components in Cassandra. 


\section{Proof of concept}
\paxos algorithm has a formal mathematical proof of its correctness. \cite{Lamport1998partTimeParliment} Formal proof of \emph{Mutli Partition Transactions} algorithm is out of scope for this work. Implementation of algorithm in Cassandra database is done instead, as proof of concept. 



\section{Key assumptions}
There are few assumptions as to implementation.
\begin{enumerate*}
\item  Implementation should be an extension to existing features of database - cannot break nor change specification of existing functionality
\item Algorithm’s implementation should be part of database, not an application on top of database.
\item User uses transactions according to specification, any use opposed to specification is not guaranteed to work as intended
\item Transactions should not be forced onto user, user has to use them as opt-in in a way they were designed
\item Transactions should not block normal updates - implementation won’t block user from doing non transactional updates to tables.
\end{enumerate*}

\section{Terms of use}
Implementation does not prevent user from misusing transactions. Implementation allows to use Cassandra in transactional way, but only if it is done according to specification. In principle transactions are run with other transactions whereas normal updates are completely independent from each other as well as from transactions, which means that an normal update might be perceived, as inconsistent modification of the data.

% \subsubsection{Typical use case}
% Assume bank transfers and moving money from account $acc_{1}$ to account $acc_{2}$. Each account has a balance which is reflected by transfers to and from an account.
% Moving money from one account to the other should create 
% For example, typical use case can be:
% 1. Client wants to move money to his other account.  Update balances of his accounts and record transfer to transfers table within transaction
% 2. Save request about attempt to make money transfer outside transaction using normal update


% Money transfer will either succeed or fail, but request to do so should be always saved because it runs outside transaction. This is just a simple example showing how different workloads can be mixed if required. 


% Illegal scenario from business perspective would be to update balances within transaction, but to register transfer outside transaction because if transaction fails then there is a transfer in the system that does not have reflection in accounts balances. 

\section{Transactional consistency levels}
Transactions are implemented as opt-in feature of Cassandra. New consistency levels  are introduced that represent transactional workload. Adding new levels follows convention of how new features are added to Cassandra, as was the case with \lwt. 
 
Cassandra can operate on different consistency levels performing reads and writes. Different consistency levels have different performance, but also different guarantees. Examples of consistency levels are:
\begin{description}
\item[ONE] -- read/write performed only on single node
\item[QUORUM] -- read/write performed on quorum of replicas
\item[ALL] -- read/write from/to all replicas
\item[SERIAL / LOCAL_SERIAL] -- uses \lwt to do read/write with condition
\end{description}

New transactional consistency levels are \code{TRANSACTIONAL, LOCAL_TRANSACTIONAL}. Both use \mpt, but latter is confined to the local data center.

\section{Transaction state}
Cassandra organizes tables in \emph{keyspaces}, thus transaction items need additional information about keyspace to locate data at a node. Transaction item in Cassandra becomes:

\begin{lstlisting}[language=Java,style=outcode,label={lst:txState},caption={Transaction item in Cassandra}]

class TransactionItem
{
   long token
   String keyspaceName;
   String tableName;
}
\end{lstlisting}

Keyspace and table name are always required. Type of a token is just \emph{long} type. Type of transaction id is \emph{UUID with encoded timestamp} \cite{CassandraUUID}.
% Just because table name is not enough to find it. Keyspace name is always required. Here we can also see concrete type of token which is just a plain long number.
% Transaction has unique id. I’ve used 


\section{Extending CQL}
%Cassandra uses binary protocol named Cassandra Query Language (CQL). In order to do anything with database, we need to use a driver that speaks binary protocol. 
%I’ve used Cassandra Java Driver which is most standard implementation of C* driver.
Cassandra Query Language has been extended to support new functionality and new statements. Adding any new feature to CQL requires a change to its syntax. I wanted to reuse as much of functionality as possible, but I had to modify syntax of: insert, update and delete statements. Fortunately all modification statements share same \emph{USING} clause, as in examples \ref{lst:insertUsing}, \ref{lst:updateUsing} which can be used to represent modification in a transaction.

\begin{lstlisting}[style=outcode,label={lst:insertUsing},caption={Insert statement with using clause}]
INSERT INTO ks.users VALUES(...) 
WHERE ... 
USING TIMESTAMP = <timestamp>;
\end{lstlisting}

\begin{lstlisting}[style=outcode,label={lst:updateUsing},caption={Update statement with using clause}]
UPDATE ks.users 
USING TIMESTAMP = <timestamp> 
SET ...
WHERE ...;
\end{lstlisting}


Therefore it is possible to only extend \code{using} clause to add new functionality to all statements. Extended \code{using} clause supports \code{transaction} keyword and accept transaction id, as in example \ref{lst:insertUsingTx}. An example of transaction id is \code{32e4d520-15aa-11e6-b55d-bd89c88d765a}.


\begin{lstlisting}[style=outcode,label={lst:insertUsingTx},caption={Insert statement with using transactional clause}]
INSERT INTO ks.users VALUES(...) 
WHERE ...
USING TRANSACTION = <transaction id>;
\end{lstlisting}

% example of tx id 

Normal modifications do not have any results in the response. However in case of transactional modification, response has results set with transaction item that can be merged into transaction state by the client.

Additional \emph{CQL} syntax is added to
\begin{enumerate*}
\item Start transaction
\item Commit transaction
\item Rollback transaction
\item Read contents of private memtable - that’s a technical statement that helped in development and tests
\item Flush private memtable contents locally - another technical statement that moves data of given transaction from private memtable storage to real tables.
\end{enumerate*}

\begin{description}
\item[Start transaction statement] \hfill \\ \code{START TRANSACTION;} \\
Statement uses \code{START} keyword instead of \code{BEGIN} in order to avoid conflict with existing \code{BEGIN BATCH} statement. Response has result set with single row which represents initial empty transaction state. 
 Important fact is that transaction id is generated inside cluster. Since cluster nodes have their system clocks synchronized, then timestamp encoded in \code{UUID} is reliable. Timestamp can be used for different operations, such as tracking how long transaction existed.
\item[Commit transaction statement] \hfill \\ \code{COMMIT TRANSACTION AS JSON <transaction state as json>;} \\ Client has to serialize Transaction State into json and execute commit statement. Only client has transaction state with all transaction items existing in the cluster for that transaction.
\item[Rollback transaction statement] \hfill \\ \code{ROLLBACK TRANSACTION AS JSON <transaction state as json>;} \\
Transaction State is also required in order to send rollback messages only to nodes which have some data associated with transaction.
\end{description}



\section{Write path extensions}
Write path of Cassandra \cite{CassandraWritePath} was modified in order to support transactional writes to private memtables. 
Transactional data is only kept in-memory, therefore write is acknowledged by coordinator node as soon as modification has been written to quorum of replica nodes.


Write path has been extended by detecting whether \emph{using transaction} clause has been used and if so if transaction id is present. All changes to data in Cassandra are represented by \code{Mutation} class. If transaction is detected, mutation is wrapped with \code{TransactionalMutation} which besides having mutation has also transaction id.
When transactional mutation is applied by its apply method, all the changes go to Private Transaction Storage instead of main tables.


\section{Read path extensions}
Read path \cite{CassandraReadPath} was also modified. Syntax of select statement stays without changes, because logic of executing select depends only on consistency level used to execute query.  When select is performed with one of new consistency levels, then coordinator performs transactional read.


Transactional read guarantees that it will read consistent data and finish any in progress transactions that can be found. It runs MPP round, but completes early when there are no in progress proposals or when it has repaired all in progress transactions.


Principles of implementation are similar to LWT, but details differ.


Since we want to reuse MPP code we need to create a read-only transaction with single transaction item representing key which we want to select. For read transactions, MPP can start assuming all transactions are already in pre prepare phase. Since read transaction is represented by same Transaction State data structure, we need to convey information that it is indeed read-only transaction. Simple implementation could add another flag which would be worthless for all other use cases. I’ve decided to convey read-only information in the timestamp of transaction by creating a UUID from timestamp far in the future. This way, there is no need for modifications to Transaction State data structure. This special read-only transaction state is only used between cluster nodes so internal details are not visible to the client.


Transaction Index seeing read-only transaction will return paxos round id with first conflicting transaction it can find. There is no need to register read-only transaction anywhere, because it has to be invisible to other transactions.


Transactional read algorithm looks as follows:
1. Select query for key K with transactional CL
2. Create read-only transaction state
   1. It has single transaction item with token from K, keyspace and table as in query
1. Run MPP round starting with replicas in pre prepared phase
2. Execute MPP until it has successfully transitioned into prepare phase
   1. If there is in progress proposal with transaction, try to complete it
1. Perform normal read with CL=Quorum


Read is only performed when coordinator has became a leader and completed all of in progress transactions. In such case tables such have only committed data. Quorum consistency level is used for normal read, because MPP relies at least quorum being consistent.




\section{Private Transaction Storage}
\emph{Private Transaction Storage} implementation which uses private \emph{memtables} to store transaction's modifications. It maps transaction id to its data \code{TransactionData}. Transaction data stores \emph{mutations} mapped by keyspace, table and \textbf{full key}, thus storage has information about which keys are modified in transaction. Each owned transaction item has corresponding entry in transaction data map.

When new modification is done in trasaction, then new mutation is added to transaction data. It is either merged with already present mutation for same partition key, or it is added as new entry in the map.


\subsection{Applying changes locally}
When transaction is committed at node, its data is applied to targeted tables.
Since Cassandra uses timestamps to detect most recent writes all partition updates -- stored in mutations -- have to be written with timestamp that comes from paxos ballot. Since mutations were added at arbitrary time during execution of transaction, their timestamps have to be modified. Concretely binary trees with data stored in \code{PartitionUpdates} have to be transformed into new binary trees with all timestamps updated to ballot's timestamp. Fortunately, Cassandra provides a method to rewrite binary trees with updated timestamps.


\subsection{In memory data}
Implementation of private transaction storage keeps data only in-memory. There is a risk that given many transactions Cassandra runs out of memory. However transactions are supposed to be short lived. Number of concurrent transactions can be even controlled by client of the cluster. 
Another issue can be raised that data is lost when node shuts down and comes back immediately. In that case transaction’s private data is at this node. However data is saved to quorum of replicas. General assumption is that at least quorum of nodes should stay alive during transaction’s life span. On these grounds, we can argue that in-memory storage is sufficient for transactions.



\section{Transaction Index}
Index needs to be thread-safe and stay consistent when many concurrent transactions try to register. One solution is to create global lock on index, but this can cause contention. Other solution with less contention uses many locks acquired per transaction item owned by the node. 

\subsection{Locking of index}
Index is a map from \code{MppIndexKey} to \code{MppParticipants}. Index keys are computed from transaction state’s items owned by this node. Each transaction Item is mapped into index key by one conflict function. That results in set of index keys. Locks are acquired from map of locks accessed by hash value of an index key. In order to avoid deadlock, index keys have to be sorted so that locks are acquired in same order by different transactions. Locks are released in reversed order.


\subsection{Registration in index}
When transaction wants to register in index, it first has to acquire it. Then \code{MpPaxosParticipant} is created for this transaction. All participants from all index keys are iterated over and checked if there is a single paxos round id. If there are more potential rounds, transaction cannot be registered. Given at most one paxos round id, new participant is added to participants for all computed index keys.


\section{Configurable conflict functions}
The implementation provides configuration of conflict functions per column family, enabling different choice of conflict functions for different tables depending on intended workload.

Per table configuration is an additional feature to the algorithm implemented using column family metadata, which can be changed dynamically at runtime of the cluster by executing \code{ALTER TABLE} commands. Listing \ref{lst:configureConflictFunctions} shows how the conflict function is set to resolve conflict on same token range slice number, which puts bounds on number of concurrent transactions in table \code{sliced_counters} to $2000$ transactions. 

\begin{lstlisting}[style=outcode,label={lst:configureConflictFunctions},caption={Configuring conflict function on Cassandra table}]
CREATE TABLE counters.sliced_counters 
   (id uuid, counter1 int, counter2 int, PRIMARY KEY (id));


ALTER TABLE counters.sliced_counters WITH extensions = { 
   'transaction_conflict_bounds' : 'TOKEN_RANGE_SLICES', 
   'token_range_slices' : '2000' };
\end{lstlisting}

%It will divide token range into 2000 even slices. Such configuration allows to have at most 2000 transactions running on single node for that particular table.

Conflict functions \ref{sec:theory:conflictFunctions} are available with following names:
\begin{enumerate*}
\item \code{COMMON_TX_ITEMS} -- conflict on same transaction items, used as the default conflict function,
\item \code{TOKEN_RANGE_SLICES} -- conflict on same token range slice number. Function has additional configurable parameter \code{int token_range_slices}
\item \code{ONE_FOR_ALL} -- conflict on same table.
\end{enumerate*}

\section{Transaction Log}
Transaction log is implemented using cassandra table local to each node. 
Committed transactions are added to the table with flag \code{commited = true}. 
% Since transaction log needs to preserve information about transaction after transaction is done it is better to keep it off memory. I’ve implemented it using cassandra table local to each node. 


\section{Paxos State}
Paxos state is implemented as a table in \emph{system} keyspace, which is local to each node and is not replicated, and stores information about paxos round's state, as in the listing \ref{lst:paxosStateImpl}.

\begin{lstlisting}[style=outcode,label={lst:paxosStateImpl},caption={Table definition for multi partition transactions paxos state}]
CREATE TABLE mpt_paxos (
paxos_id UUID,
in_progress_ballot timeuuid,
most_recent_commit blob,
most_recent_commit_at timeuuid,
most_recent_commit_version int,
proposal blob,
proposal_ballot timeuuid,
proposal_version int,
PRIMARY KEY (paxos_id))
\end{lstlisting}


\section{Replica Groups Phases Executor}
Replica groups phases executor is the implementation of the state machine that performs transition operations on the replicas, and moves them in phases according to the specification.

Phases need to be compared with each other for their advancement. Enums with proper ordering of enum values is suitable for java implementation.

\begin{lstlisting}[style=outcode,label={lst:phaseEnum},caption={Phase enum}]
public enum Phase
{
   NO_PHASE,
   ROLLBACK_PHASE,
   PRE_PREPARE_PHASE,
   BEGIN_AND_REPAIR_PHASE,
   PREPARE_PHASE,
   PROPOSE_PHASE,
   COMMIT_PHASE,
   AFTER_COMMIT_PHASE;
}
\end{lstlisting}

It is important that, begin and repair phase (repairing phase) is less advanced than prepare phase. Otherwise some replicas could try to propose a new value instead of waiting until all replica groups are at least in the prepared phase.

